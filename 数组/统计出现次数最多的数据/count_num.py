# -*- coding: utf-8 -*-
# @Time : 2020/6/14 18:43
# @Author : ccs
"""

假设有上千万或上亿的数据，且数据有重复，要求统计其中出现次数最多的前n个数据。
"""

"""
思路：
1、海量日志数据，提取出某日访问百度次数最多的那个IP
分析：百度作为国内第一大搜索引擎，每天访问它的IP数量巨大，如果想一次性把所有IP数据装进内存处理，则内存容量明显不够，故针对数据太大，内存受限的情况，可以把大文件转化成（取模映射）小文件，从而大而化小，逐个处理。
换言之，先映射，而后统计，最后排序。
解法：具体分为以下3个步骤
1.分而治之/hash映射
首先把这一天访问百度日志的所有IP提取出来，然后逐个写入到一个大文件中，接着采用映射的方法，比如%1000，把整个大文件映射为1000个小文件。
2.hash_map统计
当大文件转化成了小文件，那么我们便可以采用hash_map(ip, value)来分别对1000个小文件中的IP进行频率统计，再找出每个小文件中出现频率最大的IP。
3.堆/快速排序
统计出1000个频率最大的IP后，依据各自频率的大小进行排序(可采取堆排序)，找出那个频率最大的IP，即为所求。
注：Hash取模是一种等价映射，不会存在同一个元素分散到不同小文件中去的情况，即这里采用的是%1000算法，那么同一个IP在hash后，只可能落在同一个文件中，不可能被分散的。

"""



"""
堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。堆排序可以说是一种利用堆的概念来排序的选择排序。


自我理解：
先建立好堆；
最大堆，必须大于左右节点；对左右节点的梳也采用同样规律；将最大顶点单独存放；

最大堆值默认为剩下的列表中（列表已去除了上一轮取得的最大堆顶点值）第1个元素（索引为0），
在这个条件下，分别比较左节点(与右节点)与当前最大堆根节点值，若小于则替换；

比较两边

"""
def heapify(arr,n,i):
    print("i is ",i)
    largest = i
    l =  2*i + 1
    r =  2*i + 2
    if l<n and arr[i]<arr[l]:
        largest = l
    if r<n and arr[largest] < arr[r]:
        largest = r
    if largest != i :
        arr[i],arr[largest] = arr[largest],arr[i]
        heapify(arr,n,largest)

def heap_sort(arr):
    n = len(arr)

    #构造堆
    print("range(n,-1,-1) is ",list(range(n,-1,-1)))
    for i in range(n,-1,-1):
        heapify(arr,n,i)

    for i in range(n-1,0,-1):
        arr[i],arr[0] = arr[0],arr[i]
        heapify(arr,i,0)


if __name__ == '__main__':
    arr = [12, 11, 13, 5, 6, 7]
    heap_sort(arr)
    n = len(arr)
    print("排序后")
    for i in range(n):
        print("%d" % arr[i])
